{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This is a gradual approach on using torchtext. \n",
    "\n",
    "#### Tokenize and numericalize\n",
    "We first define a `Field` which is datatype to process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = torchtext.data.Field()\n",
    "\n",
    "txt = 'This is simple sentence .'\n",
    "\n",
    "#tokenize \n",
    "tokens = field.tokenize(txt)\n",
    "print(f'tokens: {tokens}')\n",
    "\n",
    "# build the vocabulary\n",
    "field.build_vocab(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the vocab frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.vocab.freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So tokenization is happening at charecter level. so we need an interator of iterator of tokens. Lets tokenize again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = torchtext.data.Field()\n",
    "tokens = field.tokenize(txt)\n",
    "\n",
    "# we use a list of list of tokens\n",
    "field.build_vocab([tokens])\n",
    "\n",
    "#check the word frequencies\n",
    "print(f'frequencies: {field.vocab.freqs}')\n",
    "\n",
    "# words in vocab\n",
    "print(f'vocab words: {list(field.vocab.stoi.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us tokenize and numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = field.numericalize([tokens])\n",
    "print('data.shape: ', data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchifying for a language model\n",
    "When using transformers for training a language model, how do we create batches and feed the data efficiently during training?\n",
    "It was not very clear to me in https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'abcdefghijklmnopqrstuvwxyz'\n",
    "txt = ' '.join([o.upper() for o in txt])\n",
    "print(txt)\n",
    "\n",
    "rfield = torchtext.data.ReversibleField(init_token='<sos>',\n",
    "                                      eos_token='<eos>',\n",
    "                                      lower=True)\n",
    "\n",
    "tokens = rfield.tokenize(txt)\n",
    "rfield.build_vocab([tokens])\n",
    "data = rfield.numericalize([tokens])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input is tensor\n",
    "'''\n",
    "def batchify2(data, bsz):\n",
    "    # divide the data into bsz parts\n",
    "    nbatch = data.size(0)//bsz\n",
    "    \n",
    "    # trim off any extra elements that wouldnt cleanly fit (reminders)\n",
    "    data = data.narrow(0, 0, nbatch*bsz)\n",
    "    \n",
    "    # evenly divide the data across bsz batches\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A B C D E F', 'G H I J K L', 'M N O P Q R', 'S T U V W X']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = batchify2(data, bsz=4)\n",
    "print(batches.shape);\n",
    "rfield.reverse(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 3\n",
    "def get_batch(source, i):\n",
    "    print(f'source.shape: {(source.shape)}')\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source.shape: torch.Size([6, 4])\n",
      "x.shape - torch.Size([3, 4])\n",
      "y.shape - torch.Size([12])\n",
      "x: ['A B C', 'G H I', 'M N O', 'S T U']\n",
      "y: ['B H N T C I O U D J P V']\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(batches, 0)\n",
    "print(f'x.shape - {x.shape}')\n",
    "print(f'y.shape - {y.shape}')\n",
    "print(f'x: {rfield.reverse(x)}')\n",
    "print(f'y: {rfield.reverse(y.view(y.shape[0],-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/lm_batches.jpg\" width=\"480\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _generate_square_subsequent_mask(sz):\n",
    "    # populate the lower triangle with True and rest with False\n",
    "    return torch.tril(torch.ones(sz, sz)) == 1.0\n",
    "_generate_square_subsequent_mask(bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
