{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a train a neural network which can reverse a sentence. \n",
    "We will first use an encoder/decoder without attention and then try with attention. \n",
    "\n",
    "Mostly trying to re-implement https://towardsdatascience.com/attention-seq2seq-with-pytorch-learning-to-invert-a-sequence-34faf4133e53\n",
    "\n",
    "When trying to understand Attention and Transformers, I found the following posts be useful \n",
    " - https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
    " - https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3\n",
    " - https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generate a dataset of sentences and their reverse sentences of variable length.\n",
    "    \"\"\"\n",
    "    def __init__(self, words=[], min_len=5, max_len=10, type='train'):\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        # if no words are passed, let them be simple charecters\n",
    "        if not words:\n",
    "            self.words = list('abcdef')\n",
    "\n",
    "        # start of sentence\n",
    "        self.eos = '<eos>'\n",
    "        self.sos = '<sos>'\n",
    "        self.pad = '<pad>'\n",
    "\n",
    "        # complete vocab\n",
    "        self.vocab = [self.pad, self.sos, self.eos] + self.words\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.w2i = {self.vocab[idx]:idx for idx in range(len(self.vocab))}\n",
    "        self.i2w = {idx:self.vocab[idx] for idx in range(len(self.vocab))}\n",
    "\n",
    "        if type == 'train':\n",
    "            self.set = [self._sample() for _ in range(3000)]\n",
    "        else:\n",
    "            self.set = [self._sample() for _ in range(300)]\n",
    "\n",
    "    def _sample(self):\n",
    "        size = random.randint(self.min_len, self.max_len)\n",
    "\n",
    "        # ignore the last two as they are sos and eos\n",
    "        sentence = random.choices(self.words, k=size)\n",
    "        reverse = [sentence[idx] for idx in range(len(sentence)-1, -1, -1)]\n",
    "        \n",
    "        # add the sos and eos\n",
    "        sentence = [self.sos] + sentence + [self.eos]\n",
    "        reverse = [self.sos] + reverse + [self.eos]\n",
    "        # example sentence: ['<sos>', 'd', 'f', 'b', 'd', 'd', 'd', '<eos>']\n",
    "        # example reverse:  ['<sos>', 'd', 'd', 'd', 'b', 'f', 'd', '<eos>']\n",
    "        \n",
    "        # padding. Add 2 as we added sos and eos\n",
    "        sentence += [self.pad] * (self.max_len + 2 - len(sentence))\n",
    "        reverse += [self.pad] * (self.max_len + 2 - len(reverse))\n",
    "        # example sentence: ['<sos>', 'd', 'f', 'b', 'd', 'd', 'd', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
    "        # example reverse:  ['<sos>', 'd', 'd', 'd', 'b', 'f', 'd', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
    "    \n",
    "        # convert the words to integers\n",
    "        sentence_tensor = torch.LongTensor([self.w2i[word] for word in sentence])\n",
    "        reverse_tensor = torch.LongTensor([self.w2i[word] for word in reverse])\n",
    "        # example sentence: tensor([1, 6, 8, 4, 6, 6, 6, 2, 0, 0, 0, 0]) \n",
    "        # example reverse: tensor([1, 6, 6, 6, 4, 8, 6, 2, 0, 0, 0, 0])\n",
    "        \n",
    "        # return one hot encoded tensors\n",
    "        return F.one_hot(sentence_tensor, self.vocab_size).float(), F.one_hot(reverse_tensor, self.vocab_size).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.set)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.set[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see an sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 9])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ToyDataset()\n",
    "idx = random.randint(0, len(ds))\n",
    "ds[idx][0].size()\n",
    "\n",
    "# here sentence length is 12 and vocab size is 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12, 9])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(ds, batch_size=3)\n",
    "batch = next(iter(train_dl))\n",
    "batch[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input has size torch.Size([50, 15]) and output has size torch.Size([50, 5])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stacked Linear Layers with Relu\n",
    "\"\"\"\n",
    "class LinearRelu(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(LinearRelu, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for idx in range(len(hidden_sizes)):\n",
    "            if idx == 0:\n",
    "                self.layers.append(nn.Linear(input_size, hidden_sizes[idx]))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(hidden_sizes[idx-1], hidden_sizes[idx]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = self.relu(layer(x))\n",
    "        return x\n",
    "    \n",
    "# lets check this\n",
    "input_size = 15\n",
    "bs = 50\n",
    "hidden_sizes = [12, 8, 5]\n",
    "x = torch.rand((bs, input_size))\n",
    "linrel = LinearRelu(input_size, hidden_sizes)\n",
    "out = linrel(x)\n",
    "assert x.size()[1] == input_size\n",
    "assert out.size()[1] == hidden_sizes[-1]\n",
    "print(f'input has size {x.size()} and output has size {out.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will use a bidirectional LSTM to encode the input\n",
    "\"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, lstm_size):\n",
    "        super(Encoder, self).__init__()\n",
    "#         self.linear_relus = LinearRelu(input_size, hidden_sizes)\n",
    "        self.lstm = nn.LSTM(input_size, lstm_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        return out, h, c\n",
    "# class Decoder(nn.Module):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.size: torch.Size([3, 12, 9]), h.size: torch.Size([2, 3, 5]), out.size: torch.Size([3, 12, 10]), cell.size: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "lstm_size = 5\n",
    "encoder = Encoder(ds.vocab_size,lstm_size=5)\n",
    "out, h, c = encoder(batch[0])\n",
    "print(f'input.size: {batch[0].size()}, h.size: {h.size()}, out.size: {out.size()}, cell.size: {c.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
