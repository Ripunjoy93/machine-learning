{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5555e+03,  3.0718e-41,  5.0447e-44],\n",
      "        [ 0.0000e+00,         nan,  1.3567e-19],\n",
      "        [ 1.3788e-14,  3.6423e-06,  2.0699e-19],\n",
      "        [ 3.3738e-12,  7.4086e+28,  6.9397e+22],\n",
      "        [ 1.7260e+25,  2.2856e+20,  5.0948e-14]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7056,  0.2027,  0.8255],\n",
      "        [ 0.9718,  0.0176,  0.0086],\n",
      "        [ 0.5865,  0.7960,  0.3420],\n",
      "        [ 0.0570,  0.9665,  0.0342],\n",
      "        [ 0.0725,  0.9505,  0.4820]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2319,  0.4312,  0.9586],\n",
      "        [ 0.6441,  1.4629,  0.7452],\n",
      "        [ 1.1250,  0.6566,  0.9320],\n",
      "        [ 0.5526,  0.7018,  0.2179],\n",
      "        [ 0.8541,  0.9487,  1.4652]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "x = torch.rand(5,3,dtype=torch.float)\n",
    "y = torch.rand(5,3,dtype=torch.float)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if gpu is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch NN example\n",
    "With single hidden layer. Following exmaple from https://github.com/jcjohnson/pytorch-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 351.7732849121094\n",
      "100 60.04761505126953\n",
      "200 50.15278625488281\n",
      "300 68.70606231689453\n",
      "400 67.22235870361328\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#enter dimentions. N is batch size, H is neurons in hidden unit\n",
    "N, D_in, H, D_out = 32, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(D_in,H),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H,D_out)\n",
    "        )\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t%100 == 0:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    #set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch example with autograd\n",
    "We will create a network with one hidden layer, using autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36486284.0\n",
      "1 35232400.0\n",
      "2 35184760.0\n",
      "3 30626186.0\n",
      "4 21789094.0\n",
      "5 12603797.0\n",
      "6 6590522.0\n",
      "7 3505887.25\n",
      "8 2091113.375\n",
      "9 1419107.5\n",
      "10 1064328.375\n",
      "11 848205.8125\n",
      "12 699167.625\n",
      "13 587410.375\n",
      "14 499453.21875\n",
      "15 428094.78125\n",
      "16 369262.875\n",
      "17 320198.125\n",
      "18 278939.34375\n",
      "19 243886.390625\n",
      "20 214081.578125\n",
      "21 188600.0\n",
      "22 166712.96875\n",
      "23 147807.625\n",
      "24 131425.28125\n",
      "25 117162.6171875\n",
      "26 104709.015625\n",
      "27 93792.6484375\n",
      "28 84184.7734375\n",
      "29 75707.421875\n",
      "30 68218.2109375\n",
      "31 61581.3984375\n",
      "32 55688.94140625\n",
      "33 50442.3359375\n",
      "34 45756.3671875\n",
      "35 41561.265625\n",
      "36 37800.36328125\n",
      "37 34425.81640625\n",
      "38 31389.767578125\n",
      "39 28656.662109375\n",
      "40 26188.078125\n",
      "41 23955.828125\n",
      "42 21935.046875\n",
      "43 20102.482421875\n",
      "44 18437.87890625\n",
      "45 16927.97265625\n",
      "46 15555.525390625\n",
      "47 14305.275390625\n",
      "48 13165.34375\n",
      "49 12125.1513671875\n",
      "50 11174.5537109375\n",
      "51 10304.916015625\n",
      "52 9508.9296875\n",
      "53 8779.173828125\n",
      "54 8109.8427734375\n",
      "55 7495.47509765625\n",
      "56 6931.111328125\n",
      "57 6412.6083984375\n",
      "58 5936.15576171875\n",
      "59 5497.61767578125\n",
      "60 5093.91748046875\n",
      "61 4721.857421875\n",
      "62 4378.7177734375\n",
      "63 4062.305419921875\n",
      "64 3770.12451171875\n",
      "65 3500.92919921875\n",
      "66 3252.230712890625\n",
      "67 3022.279296875\n",
      "68 2809.73876953125\n",
      "69 2612.86962890625\n",
      "70 2430.489501953125\n",
      "71 2261.53369140625\n",
      "72 2104.94677734375\n",
      "73 1959.7581787109375\n",
      "74 1825.040283203125\n",
      "75 1700.04345703125\n",
      "76 1584.0128173828125\n",
      "77 1476.2501220703125\n",
      "78 1376.1131591796875\n",
      "79 1283.0869140625\n",
      "80 1196.5860595703125\n",
      "81 1116.1673583984375\n",
      "82 1041.4312744140625\n",
      "83 971.8892211914062\n",
      "84 907.2041015625\n",
      "85 846.981689453125\n",
      "86 790.90380859375\n",
      "87 738.6901245117188\n",
      "88 690.03369140625\n",
      "89 644.6943969726562\n",
      "90 602.4658813476562\n",
      "91 563.0779418945312\n",
      "92 526.3447265625\n",
      "93 492.0796203613281\n",
      "94 460.12060546875\n",
      "95 430.30340576171875\n",
      "96 402.47705078125\n",
      "97 376.504150390625\n",
      "98 352.2637634277344\n",
      "99 329.6262512207031\n",
      "100 308.49127197265625\n",
      "101 288.7506408691406\n",
      "102 270.2993469238281\n",
      "103 253.0645751953125\n",
      "104 236.9622344970703\n",
      "105 221.90992736816406\n",
      "106 207.83447265625\n",
      "107 194.6720428466797\n",
      "108 182.36508178710938\n",
      "109 170.85646057128906\n",
      "110 160.09686279296875\n",
      "111 150.02626037597656\n",
      "112 140.602294921875\n",
      "113 131.7833251953125\n",
      "114 123.52994537353516\n",
      "115 115.8104248046875\n",
      "116 108.57925415039062\n",
      "117 101.81036376953125\n",
      "118 95.46937561035156\n",
      "119 89.53282928466797\n",
      "120 83.97176361083984\n",
      "121 78.76323699951172\n",
      "122 73.88479614257812\n",
      "123 69.31449127197266\n",
      "124 65.03292083740234\n",
      "125 61.02098083496094\n",
      "126 57.25880813598633\n",
      "127 53.73603439331055\n",
      "128 50.434043884277344\n",
      "129 47.33711242675781\n",
      "130 44.4339485168457\n",
      "131 41.71165466308594\n",
      "132 39.15962219238281\n",
      "133 36.7673454284668\n",
      "134 34.52333068847656\n",
      "135 32.417945861816406\n",
      "136 30.443809509277344\n",
      "137 28.591245651245117\n",
      "138 26.85378646850586\n",
      "139 25.223642349243164\n",
      "140 23.694669723510742\n",
      "141 22.259428024291992\n",
      "142 20.911375045776367\n",
      "143 19.6474609375\n",
      "144 18.460966110229492\n",
      "145 17.346864700317383\n",
      "146 16.301294326782227\n",
      "147 15.319361686706543\n",
      "148 14.39760684967041\n",
      "149 13.532371520996094\n",
      "150 12.71976089477539\n",
      "151 11.956830024719238\n",
      "152 11.239861488342285\n",
      "153 10.56680679321289\n",
      "154 9.934577941894531\n",
      "155 9.34074878692627\n",
      "156 8.782609939575195\n",
      "157 8.258501052856445\n",
      "158 7.766258716583252\n",
      "159 7.3034749031066895\n",
      "160 6.868798732757568\n",
      "161 6.460622787475586\n",
      "162 6.076426029205322\n",
      "163 5.715510845184326\n",
      "164 5.3762431144714355\n",
      "165 5.057786464691162\n",
      "166 4.75819730758667\n",
      "167 4.476507663726807\n",
      "168 4.211689472198486\n",
      "169 3.96278715133667\n",
      "170 3.7289416790008545\n",
      "171 3.5087876319885254\n",
      "172 3.3022568225860596\n",
      "173 3.1074533462524414\n",
      "174 2.9244558811187744\n",
      "175 2.75248384475708\n",
      "176 2.590498208999634\n",
      "177 2.4383797645568848\n",
      "178 2.295408010482788\n",
      "179 2.1606504917144775\n",
      "180 2.0339739322662354\n",
      "181 1.914716124534607\n",
      "182 1.802788257598877\n",
      "183 1.6971685886383057\n",
      "184 1.5979771614074707\n",
      "185 1.5047721862792969\n",
      "186 1.4169747829437256\n",
      "187 1.3341935873031616\n",
      "188 1.2563148736953735\n",
      "189 1.1831693649291992\n",
      "190 1.1141737699508667\n",
      "191 1.0493210554122925\n",
      "192 0.9883005023002625\n",
      "193 0.9309121370315552\n",
      "194 0.8767865896224976\n",
      "195 0.825940728187561\n",
      "196 0.7779889702796936\n",
      "197 0.7329022884368896\n",
      "198 0.6904098391532898\n",
      "199 0.6504950523376465\n",
      "200 0.6127700805664062\n",
      "201 0.5773279070854187\n",
      "202 0.5439585447311401\n",
      "203 0.5125296115875244\n",
      "204 0.48284396529197693\n",
      "205 0.45496833324432373\n",
      "206 0.4287489056587219\n",
      "207 0.404010534286499\n",
      "208 0.3807511031627655\n",
      "209 0.35874950885772705\n",
      "210 0.3382015824317932\n",
      "211 0.3187595009803772\n",
      "212 0.300422728061676\n",
      "213 0.2831664979457855\n",
      "214 0.26687973737716675\n",
      "215 0.25159257650375366\n",
      "216 0.2371072918176651\n",
      "217 0.22349530458450317\n",
      "218 0.21069036424160004\n",
      "219 0.1986347883939743\n",
      "220 0.18724220991134644\n",
      "221 0.17651383578777313\n",
      "222 0.1664457619190216\n",
      "223 0.15690335631370544\n",
      "224 0.14795169234275818\n",
      "225 0.13949266076087952\n",
      "226 0.1315508633852005\n",
      "227 0.12403769046068192\n",
      "228 0.11692778766155243\n",
      "229 0.11024222522974014\n",
      "230 0.10396841913461685\n",
      "231 0.09805023670196533\n",
      "232 0.09250050038099289\n",
      "233 0.08722352981567383\n",
      "234 0.08227507025003433\n",
      "235 0.07756999880075455\n",
      "236 0.07316046953201294\n",
      "237 0.06898798793554306\n",
      "238 0.06510606408119202\n",
      "239 0.061391014605760574\n",
      "240 0.057912714779376984\n",
      "241 0.05462144687771797\n",
      "242 0.051556121557950974\n",
      "243 0.0486072413623333\n",
      "244 0.04586358368396759\n",
      "245 0.04327169805765152\n",
      "246 0.0408133827149868\n",
      "247 0.03852754458785057\n",
      "248 0.03635424003005028\n",
      "249 0.03428720682859421\n",
      "250 0.032356005162000656\n",
      "251 0.0305267795920372\n",
      "252 0.028815574944019318\n",
      "253 0.02720147743821144\n",
      "254 0.025661883875727654\n",
      "255 0.02420918084681034\n",
      "256 0.022849423810839653\n",
      "257 0.021564390510320663\n",
      "258 0.020356636494398117\n",
      "259 0.0192058514803648\n",
      "260 0.01814170554280281\n",
      "261 0.01712428405880928\n",
      "262 0.016167547553777695\n",
      "263 0.015269534662365913\n",
      "264 0.014420880004763603\n",
      "265 0.013622306287288666\n",
      "266 0.012858368456363678\n",
      "267 0.012151718139648438\n",
      "268 0.011476944200694561\n",
      "269 0.01083681546151638\n",
      "270 0.010248729959130287\n",
      "271 0.009683837182819843\n",
      "272 0.009148440323770046\n",
      "273 0.008649775758385658\n",
      "274 0.008172547444701195\n",
      "275 0.007728280499577522\n",
      "276 0.007309474050998688\n",
      "277 0.006904213689267635\n",
      "278 0.006538256071507931\n",
      "279 0.006187550723552704\n",
      "280 0.005858012940734625\n",
      "281 0.00554300332441926\n",
      "282 0.005242739804089069\n",
      "283 0.004958136472851038\n",
      "284 0.004699144512414932\n",
      "285 0.004448473919183016\n",
      "286 0.004215249326080084\n",
      "287 0.0039974479004740715\n",
      "288 0.0037904551718384027\n",
      "289 0.0035930403973907232\n",
      "290 0.003409997560083866\n",
      "291 0.0032348372042179108\n",
      "292 0.0030669549014419317\n",
      "293 0.0029111970216035843\n",
      "294 0.0027645693626254797\n",
      "295 0.0026239140424877405\n",
      "296 0.0024930399376899004\n",
      "297 0.0023715654388070107\n",
      "298 0.002248995704576373\n",
      "299 0.002137918956577778\n",
      "300 0.002034052275121212\n",
      "301 0.0019350488437339664\n",
      "302 0.0018387958407402039\n",
      "303 0.0017543331487104297\n",
      "304 0.001669617835432291\n",
      "305 0.0015906284097582102\n",
      "306 0.0015159820904955268\n",
      "307 0.0014456214848905802\n",
      "308 0.0013785125920549035\n",
      "309 0.0013166419230401516\n",
      "310 0.0012575422879308462\n",
      "311 0.0012000573333352804\n",
      "312 0.0011473590275272727\n",
      "313 0.0010962411761283875\n",
      "314 0.0010486266110092402\n",
      "315 0.0010038005420938134\n",
      "316 0.0009600796038284898\n",
      "317 0.000919223646633327\n",
      "318 0.0008798681665211916\n",
      "319 0.0008427600841969252\n",
      "320 0.0008066094596870244\n",
      "321 0.0007737773121334612\n",
      "322 0.0007426615338772535\n",
      "323 0.0007122060633264482\n",
      "324 0.0006838154513388872\n",
      "325 0.0006577793974429369\n",
      "326 0.000631042814347893\n",
      "327 0.0006070689996704459\n",
      "328 0.0005838258075527847\n",
      "329 0.0005614939727820456\n",
      "330 0.0005397691857069731\n",
      "331 0.0005186417838558555\n",
      "332 0.0004991402965970337\n",
      "333 0.0004806484212167561\n",
      "334 0.0004643104912247509\n",
      "335 0.00044841563794761896\n",
      "336 0.0004323176690377295\n",
      "337 0.00041637569665908813\n",
      "338 0.00040285271825268865\n",
      "339 0.0003877262060996145\n",
      "340 0.0003746593720279634\n",
      "341 0.00036150054074823856\n",
      "342 0.0003488773654680699\n",
      "343 0.0003381193382665515\n",
      "344 0.0003256599011365324\n",
      "345 0.00031540656345896423\n",
      "346 0.0003052238025702536\n",
      "347 0.0002951662172563374\n",
      "348 0.00028578180354088545\n",
      "349 0.00027667550602927804\n",
      "350 0.0002688048407435417\n",
      "351 0.00026069124578498304\n",
      "352 0.0002518779947422445\n",
      "353 0.00024504013708792627\n",
      "354 0.0002371357404626906\n",
      "355 0.00023043037799652666\n",
      "356 0.00022366335906554013\n",
      "357 0.0002162283199140802\n",
      "358 0.00021029704657848924\n",
      "359 0.00020449126895982772\n",
      "360 0.00019785611948464066\n",
      "361 0.00019282889843452722\n",
      "362 0.00018745873239822686\n",
      "363 0.00018280703807249665\n",
      "364 0.00017783429939299822\n",
      "365 0.0001727777998894453\n",
      "366 0.00016770105867180973\n",
      "367 0.0001634477375773713\n",
      "368 0.00015921026351861656\n",
      "369 0.0001551197492517531\n",
      "370 0.00015105654892977327\n",
      "371 0.00014740413462277502\n",
      "372 0.00014398805797100067\n",
      "373 0.00013999656948726624\n",
      "374 0.00013696501264348626\n",
      "375 0.00013365066843107343\n",
      "376 0.00012997645535506308\n",
      "377 0.00012693906319327652\n",
      "378 0.0001240251585841179\n",
      "379 0.00012119400344090536\n",
      "380 0.0001182010310003534\n",
      "381 0.00011555756645975634\n",
      "382 0.00011326684762025252\n",
      "383 0.00011044147686334327\n",
      "384 0.00010782772005768493\n",
      "385 0.00010519463830860332\n",
      "386 0.00010334652324672788\n",
      "387 0.00010075591853819788\n",
      "388 9.796296217245981e-05\n",
      "389 9.642743680160493e-05\n",
      "390 9.4085575256031e-05\n",
      "391 9.170895646093413e-05\n",
      "392 8.983187581179664e-05\n",
      "393 8.781332871876657e-05\n",
      "394 8.612203964730725e-05\n",
      "395 8.465648716082796e-05\n",
      "396 8.298317698063329e-05\n",
      "397 8.128141780616716e-05\n",
      "398 7.990486483322456e-05\n",
      "399 7.821668987162411e-05\n",
      "400 7.663280121050775e-05\n",
      "401 7.511320291087031e-05\n",
      "402 7.358155562542379e-05\n",
      "403 7.200398977147415e-05\n",
      "404 7.070186984492466e-05\n",
      "405 6.955828575883061e-05\n",
      "406 6.834315718151629e-05\n",
      "407 6.697029311908409e-05\n",
      "408 6.564439536305144e-05\n",
      "409 6.463226600317284e-05\n",
      "410 6.344771827571094e-05\n",
      "411 6.226435652934015e-05\n",
      "412 6.13570082350634e-05\n",
      "413 6.0070178733440116e-05\n",
      "414 5.908625098527409e-05\n",
      "415 5.800827784696594e-05\n",
      "416 5.6715176469879225e-05\n",
      "417 5.5753494962118566e-05\n",
      "418 5.458229497889988e-05\n",
      "419 5.386413977248594e-05\n",
      "420 5.3014649893157184e-05\n",
      "421 5.208708898862824e-05\n",
      "422 5.132069418323226e-05\n",
      "423 5.060154217062518e-05\n",
      "424 5.0043483497574925e-05\n",
      "425 4.896287646261044e-05\n",
      "426 4.839686880586669e-05\n",
      "427 4.757517672260292e-05\n",
      "428 4.665312735596672e-05\n",
      "429 4.6055673010414466e-05\n",
      "430 4.524694668361917e-05\n",
      "431 4.4497977796709165e-05\n",
      "432 4.3830783397424966e-05\n",
      "433 4.315084879635833e-05\n",
      "434 4.257815453456715e-05\n",
      "435 4.1974697523983195e-05\n",
      "436 4.14335481764283e-05\n",
      "437 4.072091542184353e-05\n",
      "438 4.009093754575588e-05\n",
      "439 3.955062129534781e-05\n",
      "440 3.87862091884017e-05\n",
      "441 3.8182490243343636e-05\n",
      "442 3.7818153941771016e-05\n",
      "443 3.705528797581792e-05\n",
      "444 3.6583416658686474e-05\n",
      "445 3.6116791306994855e-05\n",
      "446 3.572946661734022e-05\n",
      "447 3.510325768729672e-05\n",
      "448 3.459895378910005e-05\n",
      "449 3.420827488298528e-05\n",
      "450 3.372819992364384e-05\n",
      "451 3.3233125577680767e-05\n",
      "452 3.290179301984608e-05\n",
      "453 3.2447762350784615e-05\n",
      "454 3.2069903681986034e-05\n",
      "455 3.159740299452096e-05\n",
      "456 3.112893318757415e-05\n",
      "457 3.085453136009164e-05\n",
      "458 3.05018802464474e-05\n",
      "459 3.0069833883317187e-05\n",
      "460 2.9706277928198688e-05\n",
      "461 2.9240287403808907e-05\n",
      "462 2.9067998184473254e-05\n",
      "463 2.892894553951919e-05\n",
      "464 2.857992694771383e-05\n",
      "465 2.8222453693160787e-05\n",
      "466 2.7813286578748375e-05\n",
      "467 2.7627869712887332e-05\n",
      "468 2.7384261557017453e-05\n",
      "469 2.7000467525795102e-05\n",
      "470 2.667455373739358e-05\n",
      "471 2.6322202757000923e-05\n",
      "472 2.6026849809568375e-05\n",
      "473 2.5915191145031713e-05\n",
      "474 2.558181222411804e-05\n",
      "475 2.5273468054365367e-05\n",
      "476 2.501159360690508e-05\n",
      "477 2.4752342142164707e-05\n",
      "478 2.4523793399566785e-05\n",
      "479 2.43382528424263e-05\n",
      "480 2.3999389668460935e-05\n",
      "481 2.3770384359522723e-05\n",
      "482 2.3484966732212342e-05\n",
      "483 2.3235299522639252e-05\n",
      "484 2.2916559828445315e-05\n",
      "485 2.2671818442177027e-05\n",
      "486 2.234673775092233e-05\n",
      "487 2.215432505181525e-05\n",
      "488 2.1864610971533693e-05\n",
      "489 2.1729187210439704e-05\n",
      "490 2.1563291738857515e-05\n",
      "491 2.1319810912245885e-05\n",
      "492 2.101430800394155e-05\n",
      "493 2.0799394405912608e-05\n",
      "494 2.0664338080678135e-05\n",
      "495 2.0388124539749697e-05\n",
      "496 2.0187117115710862e-05\n",
      "497 2.0049796148668975e-05\n",
      "498 1.9880919353454374e-05\n",
      "499 1.9791243175859563e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#set the device\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('gpu')\n",
    "\n",
    "#dimensions of inputs and outputs. N is batch size\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "#Create input and output\n",
    "x = torch.randn(N,D_in,device=device)\n",
    "y = torch.randn(N,D_out,device=device)\n",
    "\n",
    "#initialize the weights\n",
    "w1 = torch.randn(D_in, H,device=device,requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    #predict y\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    #get the loss\n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    #compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= w1.grad * learning_rate\n",
    "        w2 -= w2.grad * learning_rate\n",
    "        \n",
    "        #set the gradients to zero\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
