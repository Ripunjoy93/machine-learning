{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "Reusable code, utils etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check if the current code is running in a notebook\n",
    "From https://stackoverflow.com/questions/15411967/how-can-i-check-if-code-is-executed-in-the-ipython-notebook\n",
    "\"\"\"\n",
    "def isnotebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_categorical_columns(df, ignore_cols=[]):\n",
    "    return [o for o in df.select_dtypes(include=['category','object']).columns if o not in ignore_cols]\n",
    "\n",
    "def get_numeric_columns(df, ignore_cols=[]):\n",
    "    return [o for o in df.select_dtypes(exclude=['category','object']).columns if o not in ignore_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "First create a sample dataframe \n",
    "\n",
    "Then we try to implement the following steps for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'n1': [1,2,3,4,5,None],\n",
    "    'c1': ['a','a','b','a',np.nan,'b'],\n",
    "    'c2': ['x',np.nan,'y',np.nan,np.nan,'x']\n",
    "})\n",
    "\n",
    "cat_cols = get_categorical_columns(df)\n",
    "cont_cols = get_numeric_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/using-columntransformer-to-combine-data-processing-steps-af383f7d5260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', 'x', -1.3333333333333333],\n",
       "       ['a', '-999', -0.6666666666666666],\n",
       "       ['b', 'y', 0.0],\n",
       "       ['a', '-999', 0.6666666666666666],\n",
       "       ['-999', '-999', 1.3333333333333333],\n",
       "       ['b', 'x', 0.0]], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline for each column groups (to ensure the sequnce)\n",
    "cat_pipe = Pipeline([('imp_cat',SimpleImputer(strategy='constant', fill_value='-999')),\n",
    "                     ])\n",
    "cont_pipe = Pipeline([('imp_cont', SimpleImputer(strategy='mean')),\n",
    "                      ('scaler', RobustScaler())])\n",
    "\n",
    "# Apply each pipline to the column groups\n",
    "col_trans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cats', cat_pipe, cat_cols),\n",
    "        ('conts', cont_pipe, cont_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "col_trans.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "remove outliers using percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(list(np.random.rand(50)) + [2.0])\n",
    "upper_bound, lower_bound = np.percentile(x, [1,99])\n",
    "x_clipped = np.clip(x, upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalers\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "\n",
    "Which scaler to choose? - https://docs.google.com/spreadsheets/d/1woVi7wq13628HJ-tN6ApaRGVZ85OdmHsDBKLAf5ylaQ/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
