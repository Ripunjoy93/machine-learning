{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install pytorch_lightning\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "\n",
    "data_dir = Path.home()/'data/kaggle/m5-forecasting-accuracy'\n",
    "\n",
    "x_cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "        'weekday', 'wday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI']\n",
    "x_cont_cols = ['sell_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    " - normalize y\n",
    " - sales price is 0. fix it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales.shape: (30490, 1919)\n",
      "CPU times: user 7.42 s, sys: 4.79 s, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sales = pd.read_csv(data_dir/'sales_train_validation.csv')\n",
    "print(f'sales.shape: {sales.shape}')\n",
    "cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "\n",
    "# encode cat cols\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    encoder =  OrdinalEncoder()\n",
    "    sales[[col]] = encoder.fit_transform(sales[[col]])\n",
    "    sales[col] = sales[col].astype(np.long)\n",
    "    encoders[col] = encoder\n",
    "    \n",
    "# change day column names to just day number\n",
    "day_cols = {col: col.split('_')[1] for col in sales.columns if col.startswith('d_')}\n",
    "sales.rename(columns=day_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num store_items -  30490\n"
     ]
    }
   ],
   "source": [
    "num_days = len(day_cols)\n",
    "num_stores = sales['store_id'].nunique()\n",
    "num_items = sales['item_id'].nunique()\n",
    "print('num store_items - ', num_stores * num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(data_dir/'calendar.csv')\\\n",
    "            .rename(columns={'d':'day'})\n",
    "\n",
    "cat_cal_cols = ['wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI']\n",
    "# ignore_cal_cols = ['wm_yr_wk']\n",
    "\n",
    "for col in cat_cal_cols:\n",
    "    \n",
    "    # impute\n",
    "    if str(calendar[col].dtype)[:3] == 'obj':\n",
    "        fill_value = 'abcxyz' \n",
    "    elif str(calendar[col].dtype)[:3] == 'int':\n",
    "        fill_value = -1\n",
    "    calendar[[col]] = SimpleImputer(strategy='constant', fill_value=fill_value).fit_transform(calendar[[col]])\n",
    "    \n",
    "    # encode\n",
    "    if col not in encoders:\n",
    "        encoders[col] = OrdinalEncoder().fit(calendar[[col]])\n",
    "    calendar[[col]] = encoders[col].transform(calendar[[col]])\n",
    "    calendar[col] = calendar[col].astype(np.long)\n",
    "    \n",
    "# change day column names to just day number\n",
    "calendar['day'] = calendar['day'].apply(lambda x: x.split('_')[1])\n",
    "calendar['day'] = calendar['day'].astype(np.long)\n",
    "\n",
    "calendar.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prices = pd.read_csv(data_dir/'sell_prices.csv')\n",
    "for col in ['store_id', 'item_id', 'wm_yr_wk']:\n",
    "    prices[[col]] = encoders[col].transform(prices[[col]])\n",
    "    prices[col] = prices[col].astype(np.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sales2 = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "                                       var_name='day', value_name='demand')\n",
    "sales2['day'] = sales2['day'].astype(np.long)\n",
    "\n",
    "sales2.sort_values('day', inplace=True)\n",
    "calendar.sort_values('day', inplace=True)\n",
    "\n",
    "sales2 = sales2.merge(calendar, on='day', how='left')\n",
    "sales2 = sales2.merge(prices, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n",
    "sales2['sell_price'] = sales2['sell_price'].astype(np.float32)\n",
    "sales2['sell_price'] = sales2['sell_price'].fillna(0.0)\n",
    "\n",
    "sales2.sort_values(['item_id', 'store_id','day'], inplace=True)\n",
    "\n",
    "# scale continuous columns\n",
    "scalers = {}\n",
    "for col in ['sell_price','demand']:\n",
    "    scaler = MinMaxScaler()\n",
    "    sales2[[col]] = scaler.fit_transform(sales2[[col]])\n",
    "    scalers[col] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales2.to_parquet('combined.pq')\n",
    "with open('encoders.pkl','wb') as f:\n",
    "    pickle.dump(encoders,f)\n",
    "    \n",
    "with open('scalers.pkl','wb') as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58327370, 22)\n",
      "CPU times: user 24.9 s, sys: 45.7 s, total: 1min 10s\n",
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'day',\n",
       "       'demand', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sales2 = pd.read_parquet('combined.pq')\n",
    "print(sales2.shape)\n",
    "sales2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 26.9 s, total: 38.7 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = torch.tensor(sales2[x_cat_cols + x_cont_cols].values)\n",
    "y = torch.tensor(sales2['demand'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id           int64\n",
       "dept_id           int64\n",
       "cat_id            int64\n",
       "store_id          int64\n",
       "state_id          int64\n",
       "weekday           int64\n",
       "wday              int64\n",
       "month             int64\n",
       "year              int64\n",
       "event_name_1      int64\n",
       "event_type_1      int64\n",
       "event_name_2      int64\n",
       "event_type_2      int64\n",
       "snap_CA           int64\n",
       "snap_TX           int64\n",
       "snap_WI           int64\n",
       "sell_price      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales2[x_cat_cols + x_cont_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 373 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from fastai v2\n",
    "def get_emb_size(nunique):\n",
    "    return min(600, round(1.6 * nunique**0.56))\n",
    "\n",
    "emb_sizes = [(sales2[col].nunique(), get_emb_size(sales2[col].nunique())) for col in x_cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emb_sz.pkl','wb') as f:\n",
    "    pickle.dump(emb_sizes,f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_size = num_items * num_stores\n",
    "# group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape - torch.Size([1913, 30490, 17]) y1.shape - torch.Size([1913, 30490])\n",
      "CPU times: user 43.7 s, sys: 10.4 s, total: 54.1 s\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_features = x.size(1)\n",
    "x1 = x.view(-1, num_days, num_features).refine_names('item_store', 'day','features')\\\n",
    "        .align_to('day','item_store','features').contiguous()\n",
    "\n",
    "y1 = y.view(-1, num_days).refine_names('item_store', 'day')\\\n",
    "    .align_to('day', 'item_store').contiguous()\n",
    "\n",
    "print(f'x1.shape - {x1.shape} y1.shape - {y1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 µs, sys: 10.1 s, total: 10.1 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(x1.rename(None), 'x.pt')\n",
    "torch.save(y1.rename(None), 'y.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5DataSet(Dataset):\n",
    "    def __init__(self,x, y, src_len, tgt_len, bsz, dstype='train'):\n",
    "        assert dstype in ['train', 'test','val']\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.src_len = src_len\n",
    "        self.tgt_len = tgt_len\n",
    "        self.bsz = bsz\n",
    "        self.dstype = dstype\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.dstype == 'train':\n",
    "            l = (self.x.size(0) - (self.src_len + self.tgt_len)) \n",
    "            return l\n",
    "        \n",
    "        if self.dstype == 'test':\n",
    "            return 1\n",
    "        \n",
    "        return l\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.dstype == 'train':\n",
    "            # we have 30490 item_stores. We may not be able to load them all. So randomly pick bsz items. \n",
    "            item_store_mask = list(np.random.randint(0, self.x.size(1),(self.bsz,)))\n",
    "        elif self.dstype == 'test':\n",
    "            item_store_mask = list(np.arange(self.x.size(1)))\n",
    "            idx = self.x.size(0) - self.src_len\n",
    "        \n",
    "        x_src = self.x.rename(None)[idx:idx+self.src_len, item_store_mask, :]\n",
    "        x_tgt = self.x.rename(None)[idx+self.src_len:idx+self.src_len+self.tgt_len, item_store_mask, :]\n",
    "        y_src = self.y.rename(None)[idx:idx+self.src_len, item_store_mask]\n",
    "        y_tgt = self.y.rename(None)[idx+self.src_len:idx+self.src_len+self.tgt_len, item_store_mask]\n",
    "#         print(f'x.shape - {self.x.shape} y.shape - {self.y.shape} idx - {idx}. x_item.shape - {x_item.shape} y_item.shape - {y_item.shape}')\n",
    "        return x_src, x_tgt, y_src, y_tgt, item_store_mask\n",
    "\n",
    "# train_ds = M5DataSet(x1, y1, src_len, tgt_len, 200)\n",
    "# train_dl = DataLoader(train_ds, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# def insert_embedding(inp, dim, index, emb):\n",
    "#     \"\"\"\n",
    "#     Replace columns with their embeddings. Works only with 2-d tensors.\n",
    "#     TODO - make it work for multi-dim tensors\n",
    "\n",
    "#     :param inp: tensor of two or more dimensions\n",
    "#     :param dim: dimension along which tensor should be expanded by inserting the embedding\n",
    "#     :param i: index of tensor along dim which is to be embedded\n",
    "#     :param emb: Embedding of shape [v,d], where v vocab_size and d is embedding dimension\n",
    "#     :return: \n",
    "#     \"\"\"\n",
    "#     # create a slice of the data to be replaced with embedding. \n",
    "#     s = inp.index_select(dim, torch.tensor([index])).squeeze(dim)\n",
    "#     embedded = emb(s.type(torch.long))\n",
    "    \n",
    "#     first_indices = torch.arange(0,index)\n",
    "#     last_indices = torch.arange(index+1,inp.size(dim))\n",
    "\n",
    "#     return torch.cat([inp.index_select(dim, first_indices), embedded.type(inp.dtype), inp.index_select(dim, last_indices)], axis=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = torch.load('x.pt')\n",
    "gy = torch.load('y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesModel(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(SalesModel, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.x_cat_cols = x_cat_cols\n",
    "        self.x_cont_cols = x_cont_cols\n",
    "        self.pos_encoder = PositionalEncoding(hparams.ninp, hparams.dropout)\n",
    "#         encoder_layers = nn.TransformerEncoderLayer(hparams.ninp, hparams.nhead, hparams.nhid, hparams.dropout)\n",
    "#         decoder_layers = nn.TransformerDecoderLayer(hparams.ninp, hparams.nhead, hparams.nhid, hparams.dropout)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layers, hparams.nlayers)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(decoder_layers, hparams.nlayers)\n",
    "#         self.lin = nn.Linear()\n",
    "        self.transformer = nn.Transformer(d_model=hparams.ninp, nhead=hparams.nhead, \n",
    "                                          num_encoder_layers=hparams.nlayers,\n",
    "                                          num_decoder_layers=hparams.nlayers,\n",
    "                                          dim_feedforward=hparams.nhid)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.lin = nn.Linear(hparams.ninp, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        print('reading data', flush=True)\n",
    "        self.x = gx\n",
    "        self.y = gy\n",
    "\n",
    "        with open('emb_sz.pkl','rb') as f:\n",
    "            emb_szs = pickle.load(f)\n",
    "        print(f'emb_szs - {emb_szs}')\n",
    "                    \n",
    "        self.embs = nn.ModuleList([nn.Embedding(e[0],e[1]) for e in emb_szs])\n",
    "        \n",
    "#     def init_weights(self):\n",
    "#         initrange = 0.1\n",
    "#         self.src_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.decoder.bias.data.zero_()\n",
    "#         self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    @staticmethod\n",
    "    def add_model_specifi_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--bsz', default=20, type=int, help='batch_size', )\n",
    "        parser.add_argument('--src-len', default=90, type=int, help='source length')\n",
    "        parser.add_argument('--tgt-len', default=28, type=int, help='target length')\n",
    "        parser.add_argument('--ninp', default=320, type=int, help='expected features in the input')\n",
    "        parser.add_argument('--nhead', default=4, type=int, help='number of attention heads')\n",
    "        parser.add_argument('--nhid', default=256, type=int, help='dimesion of feed-forward network model')\n",
    "        parser.add_argument('--nlayers', default=2, type=int, help='number of encoder layers')\n",
    "        parser.add_argument('--dropout', default=0.2, type=float, help='dropout')\n",
    "        \n",
    "        # they are not hyper params, but adding them as pytorch lightening can save them\n",
    "        parser.add_argument('--num-cat-cols', default=len(x_cat_cols), type=int, help='number of categorical columns')\n",
    "        parser.add_argument('--num-cont-cols', default=len(x_cont_cols), type=int, help='number of numeric columns')\n",
    "        return parser\n",
    "    \n",
    "#     def _generate_square_subsequent_mask(self, sz):\n",
    "#         # populate the lower triangle with True and rest with False\n",
    "#         return torch.tril(torch.ones(sz, sz)) == 1.0\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_ds = M5DataSet(self.x, self.y, self.hparams.src_len, self.hparams.tgt_len, self.hparams.bsz)  \n",
    "        print(f'train_ds.length - {len(train_ds)}')\n",
    "        train_dl = DataLoader(train_ds, batch_size=1, shuffle=True, pin_memory=True)\n",
    "        return train_dl\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_ds = M5DataSet(self.x, self.y, self.hparams.src_len, self.hparams.tgt_len, self.hparams.bsz, dstype='test')  \n",
    "        test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "        return test_dl\n",
    "\n",
    "    \n",
    "    def emb_lookups(self, xb, yb=None):\n",
    "        embs_t = []\n",
    "        for idx in range(self.hparams.num_cat_cols):\n",
    "#             print('looking up for ', idx)\n",
    "            embs_t.append(self.embs[idx](xb[:,:,idx].type(torch.long)))\n",
    "        xb_cat = torch.cat(embs_t, dim=2)\n",
    "        xb_cont = xb[:,:,self.hparams.num_cat_cols:]\n",
    "        \n",
    "        if yb is not None:\n",
    "            xb = torch.cat([xb_cat, xb_cont.type(xb_cat.dtype), yb.unsqueeze(2).type(xb_cat.dtype)], dim=2)\n",
    "        else:\n",
    "            xb = torch.cat([xb_cat, xb_cont.type(xb_cat.dtype)], dim=2)\n",
    "            \n",
    "        #pad to adjust the feature dimension\n",
    "        dim3_shortfall = self.hparams.ninp - xb.size(2)\n",
    "        assert dim3_shortfall >= 0\n",
    "        pad = nn.ConstantPad1d(padding=(0,dim3_shortfall),value=0)\n",
    "        xb = pad(xb) \n",
    "\n",
    "        return xb\n",
    "\n",
    "    def forward(self, x_src, y_src, x_tgt):\n",
    "        offset = 0\n",
    "        \n",
    "        x_src = self.emb_lookups(x_src, y_src)\n",
    "        x_tgt = self.emb_lookups(x_tgt)\n",
    "            \n",
    "        x_src = self.pos_encoder(x_src)\n",
    "#         print('shape after pos encoder - ', x_src.size())\n",
    "        out = self.transformer(x_src, x_tgt)\n",
    "#         print('shape after transformer - ', out.size())\n",
    "        out = self.sigmoid(self.lin(out))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_src, x_tgt, y_src, y_tgt, item_store_mask = batch\n",
    "        x_src = x_src.squeeze(0)\n",
    "        x_tgt = x_tgt.squeeze(0)\n",
    "        y_src = y_src.squeeze(0)\n",
    "        y_tgt = y_tgt.squeeze(0)\n",
    "        \n",
    "#         print(f'x_src.shape - {tuple(x_src.shape)} \\t x_tgt.shape - {tuple(x_tgt.shape)} \\t y_src.shape - {y_src.shape} \\t y_tgt.shape - {y_tgt.shape}')\n",
    "        yhat_tgt = self(x_src, y_src, x_tgt)\n",
    "\n",
    "        # apply the mask (due to random selection of item_stores) to output\n",
    "#         idxs = list(np.arange(0,x_src.size(1)))\n",
    "#         idxs = [1 if o in item_store_mask else 0 for o in idxs]\n",
    "#         mask = torch.tensor(idxs) * torch.ones(y_tgt.size(0), y_tgt.size(1))\n",
    "#         print(f'mask.shape: {mask.shape}')\n",
    "#         \n",
    "        loss = self.criterion((yhat_tgt).reshape(-1).type(torch.float32), (y_tgt).reshape(-1).type(torch.float32))\n",
    "        if batch_idx%10 == 0:\n",
    "            print(f'{batch_idx} loss: {loss}  yhat_tgt.sum: {yhat_tgt.sum().item()}  y_tgt.sum: {y_tgt.sum().item()}')\n",
    "            \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def test(self):\n",
    "        dl = self.test_dataloader()\n",
    "        batch = next(iter(dl))\n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data\n",
      "emb_szs - [(3049, 143), (7, 5), (3, 3), (10, 6), (3, 3), (7, 5), (7, 5), (12, 6), (6, 4), (31, 11), (5, 4), (5, 4), (3, 3), (2, 2), (2, 2), (2, 2)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cbf7d80158404b87940d6551c654cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds.length - 1795\n",
      "0 loss: 0.329624742269516  yhat_tgt.sum: 31.57564926147461  y_tgt.sum: 0.002621231979030144\n",
      "10 loss: 7.812944318175141e-07  yhat_tgt.sum: 0.03121904283761978  y_tgt.sum: 0.03407601572739188\n",
      "20 loss: 2.3384134692605585e-05  yhat_tgt.sum: 0.022272393107414246  y_tgt.sum: 0.19397116644823068\n",
      "30 loss: 1.105664068745682e-05  yhat_tgt.sum: 0.019277438521385193  y_tgt.sum: 0.10353866317169069\n",
      "40 loss: 9.619941465643933e-07  yhat_tgt.sum: 0.016730470582842827  y_tgt.sum: 0.028833551769331587\n",
      "50 loss: 2.3461093405785505e-06  yhat_tgt.sum: 0.014959679916501045  y_tgt.sum: 0.05242463958060288\n",
      "60 loss: 1.4739691323484294e-05  yhat_tgt.sum: 0.022178534418344498  y_tgt.sum: 0.163826998689384\n",
      "70 loss: 2.9955435820738785e-06  yhat_tgt.sum: 0.01608908176422119  y_tgt.sum: 0.06422018348623854\n",
      "80 loss: 1.4129650480754208e-06  yhat_tgt.sum: 0.015672950074076653  y_tgt.sum: 0.039318479685452164\n",
      "90 loss: 0.0011536155361682177  yhat_tgt.sum: 0.016710707917809486  y_tgt.sum: 1.3066841415465267\n",
      "100 loss: 1.0213204859610414e-06  yhat_tgt.sum: 0.021777916699647903  y_tgt.sum: 0.03800786369593709\n",
      "110 loss: 1.833781789173372e-05  yhat_tgt.sum: 0.02683420479297638  y_tgt.sum: 0.16906946264744432\n",
      "120 loss: 0.00014000227383803576  yhat_tgt.sum: 0.029396511614322662  y_tgt.sum: 0.4574049803407602\n",
      "130 loss: 5.957604116701987e-07  yhat_tgt.sum: 0.0406639501452446  y_tgt.sum: 0.003931847968545217\n",
      "140 loss: 5.87909539717657e-07  yhat_tgt.sum: 0.04201097413897514  y_tgt.sum: 0.0\n",
      "150 loss: 0.00780495535582304  yhat_tgt.sum: 0.0674426332116127  y_tgt.sum: 3.2332896461336826\n",
      "160 loss: 4.05404307457502e-06  yhat_tgt.sum: 0.11269960552453995  y_tgt.sum: 0.038007863695937096\n",
      "170 loss: 4.71443081551115e-06  yhat_tgt.sum: 0.13822348415851593  y_tgt.sum: 0.1415465268676278\n",
      "180 loss: 1.2881430393463233e-06  yhat_tgt.sum: 0.06092400476336479  y_tgt.sum: 0.006553079947575361\n",
      "190 loss: 3.605958045227453e-05  yhat_tgt.sum: 0.06204695999622345  y_tgt.sum: 0.22280471821756226\n",
      "200 loss: 2.363663043070119e-06  yhat_tgt.sum: 0.05575166642665863  y_tgt.sum: 0.03800786369593709\n",
      "210 loss: 8.808936513560184e-07  yhat_tgt.sum: 0.05119125545024872  y_tgt.sum: 0.007863695937090433\n",
      "220 loss: 1.2021358770653023e-06  yhat_tgt.sum: 0.05863332748413086  y_tgt.sum: 0.001310615989515072\n",
      "230 loss: 1.2759605851897504e-06  yhat_tgt.sum: 0.049274742603302  y_tgt.sum: 0.01834862385321101\n",
      "240 loss: 2.8626664061448537e-06  yhat_tgt.sum: 0.06862428784370422  y_tgt.sum: 0.05504587155963303\n",
      "250 loss: 1.3831972864863928e-06  yhat_tgt.sum: 0.06683461368083954  y_tgt.sum: 0.005242463958060288\n",
      "260 loss: 6.112026653681824e-07  yhat_tgt.sum: 0.043250568211078644  y_tgt.sum: 0.0235910878112713\n",
      "270 loss: 7.780568921589293e-06  yhat_tgt.sum: 0.0708426758646965  y_tgt.sum: 0.07601572739187418\n",
      "280 loss: 1.0526844107516808e-06  yhat_tgt.sum: 0.055471405386924744  y_tgt.sum: 0.001310615989515072\n",
      "290 loss: 2.5042283596121706e-05  yhat_tgt.sum: 0.07077163457870483  y_tgt.sum: 0.26736566186107474\n",
      "300 loss: 2.2010983684594976e-06  yhat_tgt.sum: 0.09494490921497345  y_tgt.sum: 0.04062909567496724\n",
      "310 loss: 4.145418279222213e-05  yhat_tgt.sum: 0.1243155300617218  y_tgt.sum: 0.20052424639580604\n",
      "320 loss: 3.883101726387395e-06  yhat_tgt.sum: 0.09261943399906158  y_tgt.sum: 0.05111402359108781\n",
      "330 loss: 1.2478234339141636e-06  yhat_tgt.sum: 0.062171004712581635  y_tgt.sum: 0.01703800786369594\n",
      "340 loss: 1.6017633015508181e-06  yhat_tgt.sum: 0.061981476843357086  y_tgt.sum: 0.028833551769331587\n",
      "350 loss: 6.655749984929571e-06  yhat_tgt.sum: 0.03833577409386635  y_tgt.sum: 0.11664482306684142\n",
      "360 loss: 1.2998026477362146e-06  yhat_tgt.sum: 0.04801783710718155  y_tgt.sum: 0.03800786369593709\n",
      "370 loss: 6.638853164986358e-07  yhat_tgt.sum: 0.043743640184402466  y_tgt.sum: 0.0\n",
      "380 loss: 2.4205406589317136e-05  yhat_tgt.sum: 0.0355527326464653  y_tgt.sum: 0.17562254259501964\n",
      "390 loss: 1.3827738030158798e-06  yhat_tgt.sum: 0.0538686141371727  y_tgt.sum: 0.031454783748361734\n",
      "400 loss: 1.767718276823871e-05  yhat_tgt.sum: 0.053094957023859024  y_tgt.sum: 0.13368283093053734\n",
      "410 loss: 1.6379049156967085e-06  yhat_tgt.sum: 0.05742263048887253  y_tgt.sum: 0.023591087811271297\n",
      "420 loss: 2.7625051188806538e-06  yhat_tgt.sum: 0.053601957857608795  y_tgt.sum: 0.056356487549148106\n",
      "430 loss: 1.8172614772993256e-06  yhat_tgt.sum: 0.048374492675065994  y_tgt.sum: 0.01703800786369594\n",
      "440 loss: 1.3028945886617294e-06  yhat_tgt.sum: 0.05447590351104736  y_tgt.sum: 0.03800786369593709\n",
      "450 loss: 1.0584203664620873e-06  yhat_tgt.sum: 0.04591826722025871  y_tgt.sum: 0.0327653997378768\n",
      "460 loss: 7.824781960152905e-07  yhat_tgt.sum: 0.04372669756412506  y_tgt.sum: 0.015727391874180867\n",
      "470 loss: 1.52783729845396e-06  yhat_tgt.sum: 0.036147162318229675  y_tgt.sum: 0.02490170380078637\n",
      "480 loss: 1.2942307876073755e-05  yhat_tgt.sum: 0.06605556607246399  y_tgt.sum: 0.1559633027522936\n",
      "490 loss: 3.9757451304467395e-06  yhat_tgt.sum: 0.04322745278477669  y_tgt.sum: 0.08781127129750983\n",
      "500 loss: 1.4538314871970215e-06  yhat_tgt.sum: 0.048543572425842285  y_tgt.sum: 0.05897771952817825\n",
      "510 loss: 1.3582846349891042e-06  yhat_tgt.sum: 0.06264884769916534  y_tgt.sum: 0.007863695937090433\n",
      "520 loss: 9.083361760531261e-07  yhat_tgt.sum: 0.05126422643661499  y_tgt.sum: 0.024901703800786372\n",
      "530 loss: 9.158068223769078e-07  yhat_tgt.sum: 0.04879163205623627  y_tgt.sum: 0.024901703800786372\n",
      "540 loss: 2.018749000853859e-06  yhat_tgt.sum: 0.049664661288261414  y_tgt.sum: 0.04062909567496724\n",
      "550 loss: 1.6979776773951016e-05  yhat_tgt.sum: 0.06461608409881592  y_tgt.sum: 0.06422018348623854\n",
      "560 loss: 6.4632881731085945e-06  yhat_tgt.sum: 0.0720350593328476  y_tgt.sum: 0.10615989515072083\n",
      "570 loss: 1.1247834663663525e-06  yhat_tgt.sum: 0.05399809777736664  y_tgt.sum: 0.01834862385321101\n",
      "580 loss: 1.4795831475566956e-06  yhat_tgt.sum: 0.06324716657400131  y_tgt.sum: 0.014416775884665795\n",
      "590 loss: 0.00033972194069065154  yhat_tgt.sum: 0.06131749600172043  y_tgt.sum: 0.6802096985583225\n",
      "600 loss: 1.543372945889132e-06  yhat_tgt.sum: 0.06793063879013062  y_tgt.sum: 0.05766710353866317\n",
      "610 loss: 1.868200797616737e-06  yhat_tgt.sum: 0.0791735053062439  y_tgt.sum: 0.02228047182175623\n",
      "620 loss: 7.985217962414026e-06  yhat_tgt.sum: 0.06828105449676514  y_tgt.sum: 0.09829619921363042\n",
      "630 loss: 6.826310254837153e-07  yhat_tgt.sum: 0.047857463359832764  y_tgt.sum: 0.015727391874180867\n",
      "640 loss: 1.870021378636011e-06  yhat_tgt.sum: 0.04018888995051384  y_tgt.sum: 0.03931847968545216\n",
      "650 loss: 2.531841710151639e-05  yhat_tgt.sum: 0.045366980135440826  y_tgt.sum: 0.19528178243774574\n",
      "660 loss: 1.3598154282590258e-06  yhat_tgt.sum: 0.06229756772518158  y_tgt.sum: 0.03407601572739188\n",
      "670 loss: 6.611701337533304e-07  yhat_tgt.sum: 0.04501824080944061  y_tgt.sum: 0.01834862385321101\n",
      "680 loss: 1.1128437336083152e-06  yhat_tgt.sum: 0.03706829249858856  y_tgt.sum: 0.04849279161205766\n",
      "690 loss: 9.80043523668428e-07  yhat_tgt.sum: 0.04541422799229622  y_tgt.sum: 0.010484927916120577\n",
      "700 loss: 7.554845637969265e-07  yhat_tgt.sum: 0.04687570780515671  y_tgt.sum: 0.003931847968545217\n",
      "710 loss: 1.4898927247486426e-06  yhat_tgt.sum: 0.04339100047945976  y_tgt.sum: 0.0327653997378768\n",
      "720 loss: 1.7329305137536721e-06  yhat_tgt.sum: 0.050233080983161926  y_tgt.sum: 0.057667103538663174\n",
      "730 loss: 2.0233699160598917e-06  yhat_tgt.sum: 0.06341297924518585  y_tgt.sum: 0.07470511140235911\n",
      "740 loss: 7.321234988921788e-06  yhat_tgt.sum: 0.05149853974580765  y_tgt.sum: 0.07339449541284404\n",
      "750 loss: 6.354001470754156e-06  yhat_tgt.sum: 0.061990782618522644  y_tgt.sum: 0.08256880733944955\n",
      "760 loss: 2.8274273518036352e-06  yhat_tgt.sum: 0.0657821074128151  y_tgt.sum: 0.060288335517693324\n",
      "770 loss: 2.1390403617260745e-06  yhat_tgt.sum: 0.07732807099819183  y_tgt.sum: 0.05111402359108781\n",
      "780 loss: 5.18444767294568e-06  yhat_tgt.sum: 0.04721441864967346  y_tgt.sum: 0.09436435124508519\n",
      "790 loss: 1.6791624375400716e-06  yhat_tgt.sum: 0.05314154922962189  y_tgt.sum: 0.05242463958060288\n",
      "800 loss: 5.12721862833132e-06  yhat_tgt.sum: 0.061388738453388214  y_tgt.sum: 0.09305373525557012\n",
      "810 loss: 1.2848616961491643e-06  yhat_tgt.sum: 0.05536700040102005  y_tgt.sum: 0.03407601572739188\n",
      "820 loss: 1.9502301711327164e-06  yhat_tgt.sum: 0.04423386603593826  y_tgt.sum: 0.039318479685452164\n",
      "830 loss: 3.85341763831093e-06  yhat_tgt.sum: 0.0585387647151947  y_tgt.sum: 0.061598951507208385\n",
      "840 loss: 1.0895394098042743e-06  yhat_tgt.sum: 0.04268965125083923  y_tgt.sum: 0.039318479685452164\n",
      "850 loss: 5.7069560170930345e-06  yhat_tgt.sum: 0.07996363192796707  y_tgt.sum: 0.13761467889908258\n",
      "860 loss: 1.658487576605694e-06  yhat_tgt.sum: 0.08361902832984924  y_tgt.sum: 0.0327653997378768\n",
      "870 loss: 2.1079686121083796e-06  yhat_tgt.sum: 0.08168934285640717  y_tgt.sum: 0.003931847968545217\n",
      "880 loss: 6.952333933440968e-06  yhat_tgt.sum: 0.06172030046582222  y_tgt.sum: 0.10222804718217562\n",
      "890 loss: 0.00014533376088365912  yhat_tgt.sum: 0.06428094208240509  y_tgt.sum: 0.6277850589777195\n",
      "900 loss: 1.3416654383036075e-06  yhat_tgt.sum: 0.06380142271518707  y_tgt.sum: 0.002621231979030144\n",
      "910 loss: 2.921525037891115e-06  yhat_tgt.sum: 0.06392839550971985  y_tgt.sum: 0.031454783748361734\n",
      "920 loss: 6.660686722170794e-06  yhat_tgt.sum: 0.058717500418424606  y_tgt.sum: 0.12057667103538663\n",
      "930 loss: 1.939585445143166e-06  yhat_tgt.sum: 0.08233623206615448  y_tgt.sum: 0.028833551769331587\n",
      "940 loss: 9.269027032132726e-06  yhat_tgt.sum: 0.10688412189483643  y_tgt.sum: 0.10484927916120577\n",
      "950 loss: 1.99532132683089e-06  yhat_tgt.sum: 0.0785265564918518  y_tgt.sum: 0.01834862385321101\n",
      "960 loss: 7.886936828072066e-07  yhat_tgt.sum: 0.049267977476119995  y_tgt.sum: 0.001310615989515072\n",
      "970 loss: 9.544003660266753e-06  yhat_tgt.sum: 0.14227785170078278  y_tgt.sum: 0.057667103538663174\n",
      "980 loss: 2.9262144380481914e-05  yhat_tgt.sum: 0.09082834422588348  y_tgt.sum: 0.27916120576671033\n",
      "990 loss: 1.683382834016811e-06  yhat_tgt.sum: 0.07476012408733368  y_tgt.sum: 0.011795543905635648\n",
      "1000 loss: 3.6555125006998423e-06  yhat_tgt.sum: 0.12337159365415573  y_tgt.sum: 0.05373525557011796\n",
      "1010 loss: 1.2758061529893894e-05  yhat_tgt.sum: 0.0883064866065979  y_tgt.sum: 0.12844036697247707\n",
      "1020 loss: 9.821963431022596e-06  yhat_tgt.sum: 0.06936051696538925  y_tgt.sum: 0.11926605504587157\n",
      "1030 loss: 4.227101726428373e-07  yhat_tgt.sum: 0.035468392074108124  y_tgt.sum: 0.0\n",
      "1040 loss: 2.5425502826692536e-05  yhat_tgt.sum: 0.053349800407886505  y_tgt.sum: 0.16251638269986896\n",
      "1050 loss: 1.6306793213516357e-06  yhat_tgt.sum: 0.05278981849551201  y_tgt.sum: 0.038007863695937096\n",
      "1060 loss: 1.5540834965577233e-06  yhat_tgt.sum: 0.05980703979730606  y_tgt.sum: 0.015727391874180867\n",
      "1070 loss: 6.563919328073098e-07  yhat_tgt.sum: 0.037753887474536896  y_tgt.sum: 0.014416775884665792\n",
      "1080 loss: 2.347694817217416e-06  yhat_tgt.sum: 0.05065008997917175  y_tgt.sum: 0.047182175622542594\n",
      "1090 loss: 4.429848195286468e-05  yhat_tgt.sum: 0.06774426251649857  y_tgt.sum: 0.29882044560943644\n",
      "1100 loss: 2.0812299226236064e-06  yhat_tgt.sum: 0.08296240121126175  y_tgt.sum: 0.019659239842726082\n",
      "1110 loss: 2.3554128347313963e-05  yhat_tgt.sum: 0.07416211813688278  y_tgt.sum: 0.16251638269986893\n",
      "1120 loss: 1.6430121831945144e-06  yhat_tgt.sum: 0.06995926052331924  y_tgt.sum: 0.002621231979030144\n",
      "1130 loss: 2.918052132372395e-06  yhat_tgt.sum: 0.11512941867113113  y_tgt.sum: 0.07470511140235911\n",
      "1140 loss: 4.666986569645815e-06  yhat_tgt.sum: 0.1137433797121048  y_tgt.sum: 0.0\n",
      "1150 loss: 5.007721483707428e-06  yhat_tgt.sum: 0.07289393246173859  y_tgt.sum: 0.12581913499344693\n",
      "1160 loss: 3.4110121305275243e-06  yhat_tgt.sum: 0.05309082195162773  y_tgt.sum: 0.06684141546526869\n",
      "1170 loss: 1.06287711787445e-06  yhat_tgt.sum: 0.05086727440357208  y_tgt.sum: 0.01703800786369594\n",
      "1180 loss: 1.6367887383239577e-06  yhat_tgt.sum: 0.048619624227285385  y_tgt.sum: 0.039318479685452164\n",
      "1190 loss: 2.8576857857842697e-06  yhat_tgt.sum: 0.042363040149211884  y_tgt.sum: 0.06815203145478375\n",
      "1200 loss: 4.747833827423165e-06  yhat_tgt.sum: 0.05954580754041672  y_tgt.sum: 0.07863695937090431\n",
      "1210 loss: 1.0122331559614395e-06  yhat_tgt.sum: 0.04559694975614548  y_tgt.sum: 0.011795543905635648\n",
      "1220 loss: 5.85889620197122e-06  yhat_tgt.sum: 0.06836985796689987  y_tgt.sum: 0.04849279161205767\n",
      "1230 loss: 8.272621926153079e-06  yhat_tgt.sum: 0.08654816448688507  y_tgt.sum: 0.10353866317169072\n",
      "1240 loss: 2.1716004994232208e-06  yhat_tgt.sum: 0.08057978004217148  y_tgt.sum: 0.0\n",
      "1250 loss: 1.677020190982148e-05  yhat_tgt.sum: 0.08266119658946991  y_tgt.sum: 0.06684141546526869\n",
      "1260 loss: 1.8002068600253551e-06  yhat_tgt.sum: 0.08412754535675049  y_tgt.sum: 0.026212319790301444\n",
      "1270 loss: 2.1822952476213686e-05  yhat_tgt.sum: 0.10303249955177307  y_tgt.sum: 0.21494102228047185\n",
      "1280 loss: 1.6715143829060253e-06  yhat_tgt.sum: 0.07227405905723572  y_tgt.sum: 0.04193971166448231\n",
      "1290 loss: 1.5223399714159314e-06  yhat_tgt.sum: 0.05900438129901886  y_tgt.sum: 0.04849279161205767\n",
      "1300 loss: 5.695263780580717e-07  yhat_tgt.sum: 0.04557709023356438  y_tgt.sum: 0.010484927916120577\n",
      "1310 loss: 1.597080881765578e-05  yhat_tgt.sum: 0.05892300233244896  y_tgt.sum: 0.145478374836173\n",
      "1320 loss: 1.878086095530307e-06  yhat_tgt.sum: 0.07705669105052948  y_tgt.sum: 0.06815203145478374\n",
      "1330 loss: 1.387111183248635e-06  yhat_tgt.sum: 0.05826384574174881  y_tgt.sum: 0.039318479685452164\n",
      "1340 loss: 8.79575964063406e-07  yhat_tgt.sum: 0.05347084254026413  y_tgt.sum: 0.005242463958060288\n",
      "1350 loss: 1.0706323791964678e-06  yhat_tgt.sum: 0.051122743636369705  y_tgt.sum: 0.007863695937090433\n",
      "1360 loss: 1.8472758256393718e-06  yhat_tgt.sum: 0.0766206830739975  y_tgt.sum: 0.014416775884665795\n",
      "1370 loss: 1.3283485031934106e-06  yhat_tgt.sum: 0.05376168712973595  y_tgt.sum: 0.028833551769331587\n",
      "1380 loss: 5.268815584713593e-05  yhat_tgt.sum: 0.04846426099538803  y_tgt.sum: 0.17955439056356487\n",
      "1390 loss: 1.7628468640396022e-06  yhat_tgt.sum: 0.04566076397895813  y_tgt.sum: 0.038007863695937096\n",
      "1400 loss: 4.077563062310219e-06  yhat_tgt.sum: 0.0822548046708107  y_tgt.sum: 0.0655307994757536\n",
      "1410 loss: 8.455171155219432e-06  yhat_tgt.sum: 0.06380550563335419  y_tgt.sum: 0.12581913499344693\n",
      "1420 loss: 2.0121865418332163e-06  yhat_tgt.sum: 0.07688926160335541  y_tgt.sum: 0.03014416775884666\n",
      "1430 loss: 7.786931746522896e-06  yhat_tgt.sum: 0.14870910346508026  y_tgt.sum: 0.0\n",
      "1440 loss: 4.421342055138666e-06  yhat_tgt.sum: 0.11970040202140808  y_tgt.sum: 0.010484927916120577\n",
      "1450 loss: 6.443675601985888e-07  yhat_tgt.sum: 0.04415769502520561  y_tgt.sum: 0.0\n",
      "1460 loss: 3.4565968576316664e-07  yhat_tgt.sum: 0.0323370061814785  y_tgt.sum: 0.002621231979030144\n",
      "1470 loss: 1.987941004699678e-06  yhat_tgt.sum: 0.03620009124279022  y_tgt.sum: 0.03800786369593709\n",
      "1480 loss: 2.9305186899364344e-07  yhat_tgt.sum: 0.02809767797589302  y_tgt.sum: 0.002621231979030144\n",
      "1490 loss: 4.400914406232914e-07  yhat_tgt.sum: 0.03689216449856758  y_tgt.sum: 0.005242463958060288\n",
      "1500 loss: 1.526396999906865e-06  yhat_tgt.sum: 0.05132004991173744  y_tgt.sum: 0.03800786369593709\n",
      "1510 loss: 4.657828867493663e-06  yhat_tgt.sum: 0.068744957447052  y_tgt.sum: 0.04849279161205766\n",
      "1520 loss: 1.1502727829793002e-05  yhat_tgt.sum: 0.07889145612716675  y_tgt.sum: 0.13761467889908258\n",
      "1530 loss: 4.317295861255843e-06  yhat_tgt.sum: 0.1397792398929596  y_tgt.sum: 0.10222804718217562\n",
      "1540 loss: 2.0384240997373126e-06  yhat_tgt.sum: 0.08527637273073196  y_tgt.sum: 0.04456094364351245\n",
      "1550 loss: 9.394849485033774e-07  yhat_tgt.sum: 0.05199696868658066  y_tgt.sum: 0.007863695937090433\n",
      "1560 loss: 1.6054161733336514e-06  yhat_tgt.sum: 0.06775114685297012  y_tgt.sum: 0.03800786369593709\n",
      "1570 loss: 3.584067599149421e-05  yhat_tgt.sum: 0.08610352128744125  y_tgt.sum: 0.14285714285714285\n",
      "1580 loss: 1.2362563666101778e-06  yhat_tgt.sum: 0.05670827627182007  y_tgt.sum: 0.015727391874180863\n",
      "1590 loss: 3.5502562241163105e-06  yhat_tgt.sum: 0.042646121233701706  y_tgt.sum: 0.031454783748361734\n",
      "1600 loss: 7.153909973567352e-05  yhat_tgt.sum: 0.23046858608722687  y_tgt.sum: 0.4010484927916121\n",
      "1610 loss: 5.317275281413458e-06  yhat_tgt.sum: 0.10657071322202682  y_tgt.sum: 0.03407601572739188\n",
      "1620 loss: 7.504240784328431e-06  yhat_tgt.sum: 0.03212989121675491  y_tgt.sum: 0.08256880733944955\n",
      "1630 loss: 2.6278272002855374e-07  yhat_tgt.sum: 0.028205551207065582  y_tgt.sum: 0.0\n",
      "1640 loss: 0.00012934765254613012  yhat_tgt.sum: 0.043061017990112305  y_tgt.sum: 0.4285714285714286\n",
      "1650 loss: 7.777949804221862e-07  yhat_tgt.sum: 0.04082946479320526  y_tgt.sum: 0.015727391874180867\n",
      "1660 loss: 3.7328920825530076e-06  yhat_tgt.sum: 0.03604951128363609  y_tgt.sum: 0.06422018348623854\n",
      "1670 loss: 2.088964038193808e-06  yhat_tgt.sum: 0.03159986436367035  y_tgt.sum: 0.0563564875491481\n",
      "1680 loss: 5.577697379521851e-07  yhat_tgt.sum: 0.040027230978012085  y_tgt.sum: 0.0\n",
      "1690 loss: 4.527202690951526e-06  yhat_tgt.sum: 0.044281959533691406  y_tgt.sum: 0.06028833551769332\n",
      "1700 loss: 9.03209013358719e-07  yhat_tgt.sum: 0.040573060512542725  y_tgt.sum: 0.020969855832241154\n",
      "1710 loss: 1.4432548596232664e-05  yhat_tgt.sum: 0.06377719342708588  y_tgt.sum: 0.16644823066841416\n",
      "1720 loss: 7.973736501298845e-06  yhat_tgt.sum: 0.0384075865149498  y_tgt.sum: 0.0799475753604194\n",
      "1730 loss: 8.106404152385949e-07  yhat_tgt.sum: 0.04734434187412262  y_tgt.sum: 0.0\n",
      "1740 loss: 7.215922437353584e-07  yhat_tgt.sum: 0.046564359217882156  y_tgt.sum: 0.0\n",
      "1750 loss: 4.850468940276187e-06  yhat_tgt.sum: 0.06445042043924332  y_tgt.sum: 0.11009174311926606\n",
      "1760 loss: 9.316491741628852e-06  yhat_tgt.sum: 0.06754769384860992  y_tgt.sum: 0.11402359108781127\n",
      "1770 loss: 2.304415374965174e-06  yhat_tgt.sum: 0.07585306465625763  y_tgt.sum: 0.03014416775884666\n",
      "1780 loss: 1.8865610400098376e-05  yhat_tgt.sum: 0.06878197193145752  y_tgt.sum: 0.1310615989515072\n",
      "1790 loss: 2.257716687381617e-06  yhat_tgt.sum: 0.07454654574394226  y_tgt.sum: 0.0655307994757536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_len = 90\n",
    "tgt_len = 28\n",
    "# bsz = 200\n",
    "# model = SalesModel(hparams)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser = SalesModel.add_model_specifi_args(parser)\n",
    "hparams = parser.parse_args('--bsz 2 --ninp 320 --nhid 128 --nlayers 1'.split())\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='models/weights.ckpt',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# hparams.__setattr__('x_cat_cols', x_cat_cols)\n",
    "# hparams.__setattr__('x_cont_cols', x_cont_cols)\n",
    "model = SalesModel(hparams)\n",
    "trainer = Trainer(gpus=1,max_epochs=1)\n",
    "trainer.fit(model)\n",
    "trainer.save_checkpoint('models/weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data\n",
      "emb_szs - [(3049, 143), (7, 5), (3, 3), (10, 6), (3, 3), (7, 5), (7, 5), (12, 6), (6, 4), (31, 11), (5, 4), (5, 4), (3, 3), (2, 2), (2, 2), (2, 2)]\n",
      "x_src.shape - torch.Size([90, 30490, 17])\n",
      "starting inference...\n",
      "CPU times: user 4min 33s, sys: 2min 56s, total: 7min 30s\n",
      "Wall time: 24.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 30490, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = SalesModel.load_from_checkpoint('models/weights.ckpt')\n",
    "x_src, x_tgt, y_src, y_tgt, item_store_mask = model.test()\n",
    "x_src = x_src.squeeze(0)\n",
    "x_tgt = x_tgt.squeeze(0)\n",
    "y_src = y_src.squeeze(0)\n",
    "y_tgt = y_tgt.squeeze(0)\n",
    "print(f'x_src.shape - {x_src.shape}')\n",
    "\n",
    "model.eval()\n",
    "print('starting inference...')\n",
    "yhat_tgt = model(x_src, y_src, x_tgt)\n",
    "yhat_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 30490, 1), grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_store_mask = list(np.random.randint(0, 10,3))\n",
    "item_store_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(10).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
