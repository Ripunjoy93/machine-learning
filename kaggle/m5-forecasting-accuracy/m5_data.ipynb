{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install --upgrade pytorch_lightning\n",
    "# !pip install --upgarde wandb\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# from torchsummary import summary\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "\n",
    "data_dir = Path.home()/'data/kaggle/m5-forecasting-accuracy'\n",
    "\n",
    "x_cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "        'weekday', 'wday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI']\n",
    "x_cont_cols = ['sell_price']\n",
    "num_train_val_days = 1913\n",
    "num_test1_days = 28\n",
    "num_test2_days = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    " - normalize y\n",
    " - sales price is 0. fix it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar.csv                sample_submission.csv\n",
      "m5-forecasting-accuracy.zip sell_prices.csv\n",
      "sales_train_validation.csv\n"
     ]
    }
   ],
   "source": [
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales.shape: (30490, 1919)\n",
      "CPU times: user 6.1 s, sys: 2.35 s, total: 8.45 s\n",
      "Wall time: 8.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sales = pd.read_csv(data_dir/'sales_train_validation.csv')\n",
    "print(f'sales.shape: {sales.shape}')\n",
    "cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "\n",
    "# encode cat cols\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    encoder =  OrdinalEncoder()\n",
    "    sales[[col]] = encoder.fit_transform(sales[[col]])\n",
    "    sales[col] = sales[col].astype(np.long)\n",
    "    encoders[col] = encoder\n",
    "    \n",
    "# change day column names to just day number\n",
    "train_day_cols = {col: col.split('_')[1] for col in sales.columns if col.startswith('d_')}\n",
    "sales.rename(columns=train_day_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30490, 1975)\n"
     ]
    }
   ],
   "source": [
    "test_day_cols = [str(num_train_val_days + 1 + o) for o in range(56)]\n",
    "for col in test_day_cols:\n",
    "    sales[col] = 0\n",
    "print(sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  item_id  dept_id  cat_id  store_id  \\\n",
       "30488  FOODS_3_826_WI_3_validation     1435        2       0         9   \n",
       "30489  FOODS_3_827_WI_3_validation     1436        2       0         9   \n",
       "\n",
       "       state_id  1  2  3  4  ...  1960  1961  1962  1963  1964  1965  1966  \\\n",
       "30488         2  0  0  0  0  ...     0     0     0     0     0     0     0   \n",
       "30489         2  0  0  0  0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "       1967  1968  1969  \n",
       "30488     0     0     0  \n",
       "30489     0     0     0  \n",
       "\n",
       "[2 rows x 1975 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  F1  F2  F3  F4  F5  F6  F7  F8  F9  ...  \\\n",
       "60978  FOODS_3_826_WI_3_evaluation   0   0   0   0   0   0   0   0   0  ...   \n",
       "60979  FOODS_3_827_WI_3_evaluation   0   0   0   0   0   0   0   0   0  ...   \n",
       "\n",
       "       F19  F20  F21  F22  F23  F24  F25  F26  F27  F28  \n",
       "60978    0    0    0    0    0    0    0    0    0    0  \n",
       "60979    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(data_dir/'sample_submission.csv')\n",
    "sample.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total days :  1969\n",
      "num store_items -  30490\n"
     ]
    }
   ],
   "source": [
    "num_days = len(train_day_cols) + len(test_day_cols)\n",
    "num_stores = sales['store_id'].nunique()\n",
    "num_items = sales['item_id'].nunique()\n",
    "print('total days : ', num_days)\n",
    "print('num store_items - ', num_stores * num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>281</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1969</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  wm_yr_wk  weekday  wday  month  year   day  event_name_1  \\\n",
       "1967  2016-06-18       281        2     0      5     5  1968            30   \n",
       "1968  2016-06-19       281        3     1      5     5  1969            16   \n",
       "\n",
       "      event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "1967             4             4             2        0        0        0  \n",
       "1968             3             2             0        0        0        0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar = pd.read_csv(data_dir/'calendar.csv')\\\n",
    "            .rename(columns={'d':'day'})\n",
    "\n",
    "cat_cal_cols = ['wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "       'snap_CA', 'snap_TX', 'snap_WI']\n",
    "# ignore_cal_cols = ['wm_yr_wk']\n",
    "\n",
    "for col in cat_cal_cols:\n",
    "    \n",
    "    # impute\n",
    "    if str(calendar[col].dtype)[:3] == 'obj':\n",
    "        fill_value = 'abcxyz' \n",
    "    elif str(calendar[col].dtype)[:3] == 'int':\n",
    "        fill_value = -1\n",
    "    calendar[[col]] = SimpleImputer(strategy='constant', fill_value=fill_value).fit_transform(calendar[[col]])\n",
    "    \n",
    "    # encode\n",
    "    if col not in encoders:\n",
    "        encoders[col] = OrdinalEncoder().fit(calendar[[col]])\n",
    "    calendar[[col]] = encoders[col].transform(calendar[[col]])\n",
    "    calendar[col] = calendar[col].astype(np.long)\n",
    "    \n",
    "# change day column names to just day number\n",
    "calendar['day'] = calendar['day'].apply(lambda x: x.split('_')[1])\n",
    "calendar['day'] = calendar['day'].astype(np.long)\n",
    "\n",
    "calendar.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.16 s, sys: 1.11 s, total: 7.26 s\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prices = pd.read_csv(data_dir/'sell_prices.csv')\n",
    "for col in ['store_id', 'item_id', 'wm_yr_wk']:\n",
    "    prices[[col]] = encoders[col].transform(prices[[col]])\n",
    "    prices[col] = prices[col].astype(np.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6841120</th>\n",
       "      <td>9</td>\n",
       "      <td>1436</td>\n",
       "      <td>281</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220997</th>\n",
       "      <td>6</td>\n",
       "      <td>1922</td>\n",
       "      <td>281</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         store_id  item_id  wm_yr_wk  sell_price\n",
       "6841120         9     1436       281        1.00\n",
       "4220997         6     1922       281        9.97"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.sort_values('wm_yr_wk',ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achinta/miniconda3/envs/explorer/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/achinta/miniconda3/envs/explorer/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 1min 58s, total: 4min 18s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sales2 = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n",
    "                                       var_name='day', value_name='demand')\n",
    "sales2['day'] = sales2['day'].astype(np.long)\n",
    "\n",
    "sales2.sort_values('day', inplace=True)\n",
    "calendar.sort_values('day', inplace=True)\n",
    "\n",
    "sales2 = sales2.merge(calendar, on='day', how='left')\n",
    "sales2 = sales2.merge(prices, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n",
    "sales2['sell_price'] = sales2['sell_price'].astype(np.float32)\n",
    "sales2['sell_price'] = sales2['sell_price'].fillna(0.0)\n",
    "\n",
    "sales2.sort_values(['item_id', 'store_id','day'], inplace=True)\n",
    "\n",
    "# scale continuous columns\n",
    "scalers = {}\n",
    "for col in ['sell_price','demand']:\n",
    "    scaler = MinMaxScaler()\n",
    "    sales2[[col]] = scaler.fit_transform(sales2[[col]])\n",
    "    scalers[col] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales2.to_parquet('combined.pq')\n",
    "with open('encoders.pkl','wb') as f:\n",
    "    pickle.dump(encoders,f)\n",
    "    \n",
    "with open('scalers.pkl','wb') as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sales2\n",
    "del prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60034810, 22)\n",
      "CPU times: user 34.7 s, sys: 38.8 s, total: 1min 13s\n",
      "Wall time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sales2 = pd.read_parquet('combined.pq')\n",
    "print(sales2.shape)\n",
    "sales2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 35.2 s, total: 45.5 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = torch.tensor(sales2[x_cat_cols + x_cont_cols].values)\n",
    "y = torch.tensor(sales2['demand'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id           int64\n",
       "dept_id           int64\n",
       "cat_id            int64\n",
       "store_id          int64\n",
       "state_id          int64\n",
       "weekday           int64\n",
       "wday              int64\n",
       "month             int64\n",
       "year              int64\n",
       "event_name_1      int64\n",
       "event_type_1      int64\n",
       "event_name_2      int64\n",
       "event_type_2      int64\n",
       "snap_CA           int64\n",
       "snap_TX           int64\n",
       "snap_WI           int64\n",
       "sell_price      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales2[x_cat_cols + x_cont_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.72 s, sys: 2.1 s, total: 9.82 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from fastai v2\n",
    "def get_emb_size(nunique):\n",
    "    return min(600, round(1.6 * nunique**0.56))\n",
    "\n",
    "emb_sizes = [(sales2[col].nunique(), get_emb_size(sales2[col].nunique())) for col in x_cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emb_sz.pkl','wb') as f:\n",
    "    pickle.dump(emb_sizes,f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_size = num_items * num_stores\n",
    "# group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../c10/core/TensorImpl.h:806: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape - torch.Size([1969, 30490, 17]) y1.shape - torch.Size([1969, 30490])\n",
      "CPU times: user 28.2 s, sys: 22.2 s, total: 50.4 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_features = x.size(1)\n",
    "x1 = x.view(-1, num_days, num_features).refine_names('item_store', 'day','features')\\\n",
    "        .align_to('day','item_store','features').contiguous()\n",
    "\n",
    "y1 = y.view(-1, num_days).refine_names('item_store', 'day')\\\n",
    "    .align_to('day', 'item_store').contiguous()\n",
    "\n",
    "print(f'x1.shape - {x1.shape} y1.shape - {y1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.8 ms, sys: 21.6 s, total: 21.7 s\n",
      "Wall time: 35.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(x1.rename(None), 'x.pt')\n",
    "torch.save(y1.rename(None), 'y.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5DataSet(Dataset):\n",
    "    def __init__(self,x, y, src_len, tgt_len, bsz, dstype='train'):\n",
    "        assert dstype in ['train', 'test1', 'test2', 'val']\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.src_len = src_len\n",
    "        self.tgt_len = tgt_len\n",
    "        self.bsz = bsz\n",
    "        self.dstype = dstype\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.dstype == 'train':\n",
    "            l = (self.x.size(0) - (self.src_len + self.tgt_len + num_test1_days + num_test2_days)) \n",
    "            return l\n",
    "        \n",
    "        if self.dstype == 'test1':\n",
    "            return 1\n",
    "        \n",
    "        return l\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.dstype == 'train':\n",
    "            # we have 30490 item_stores. We may not be able to load them all. So randomly pick bsz items. \n",
    "            item_store_mask = list(np.random.randint(0, self.x.size(1),(self.bsz,)))\n",
    "        elif self.dstype == 'test1':\n",
    "            item_store_mask = list(np.arange(self.x.size(1)))\n",
    "            idx = self.x.size(0) - (self.src_len + self.tgt_len + num_test2_days)\n",
    "            print('test1 index - ', idx)\n",
    "        \n",
    "        x_src = self.x.rename(None)[idx:idx+self.src_len, item_store_mask, :]\n",
    "        x_tgt = self.x.rename(None)[idx+self.src_len:idx+self.src_len+self.tgt_len, item_store_mask, :]\n",
    "        y_src = self.y.rename(None)[idx:idx+self.src_len, item_store_mask]\n",
    "        y_tgt = self.y.rename(None)[idx+self.src_len:idx+self.src_len+self.tgt_len, item_store_mask]\n",
    "#         print(f'x.shape - {self.x.shape} y.shape - {self.y.shape} idx - {idx}. x_item.shape - {x_item.shape} y_item.shape - {y_item.shape}')\n",
    "        return x_src, x_tgt, y_src, y_tgt, item_store_mask\n",
    "\n",
    "# train_ds = M5DataSet(x1, y1, src_len, tgt_len, 200)\n",
    "# train_dl = DataLoader(train_ds, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# def insert_embedding(inp, dim, index, emb):\n",
    "#     \"\"\"\n",
    "#     Replace columns with their embeddings. Works only with 2-d tensors.\n",
    "#     TODO - make it work for multi-dim tensors\n",
    "\n",
    "#     :param inp: tensor of two or more dimensions\n",
    "#     :param dim: dimension along which tensor should be expanded by inserting the embedding\n",
    "#     :param i: index of tensor along dim which is to be embedded\n",
    "#     :param emb: Embedding of shape [v,d], where v vocab_size and d is embedding dimension\n",
    "#     :return: \n",
    "#     \"\"\"\n",
    "#     # create a slice of the data to be replaced with embedding. \n",
    "#     s = inp.index_select(dim, torch.tensor([index])).squeeze(dim)\n",
    "#     embedded = emb(s.type(torch.long))\n",
    "    \n",
    "#     first_indices = torch.arange(0,index)\n",
    "#     last_indices = torch.arange(index+1,inp.size(dim))\n",
    "\n",
    "#     return torch.cat([inp.index_select(dim, first_indices), embedded.type(inp.dtype), inp.index_select(dim, last_indices)], axis=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gx = torch.load('x.pt')\n",
    "gy = torch.load('y.pt')\n",
    "print(f'gx.shape - {gx.shape} gy.shape - {gy.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesModel(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(SalesModel, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        self.x_cat_cols = x_cat_cols\n",
    "        self.x_cont_cols = x_cont_cols\n",
    "        self.pos_encoder = PositionalEncoding(hparams.ninp, hparams.dropout)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(hparams.ninp, hparams.nhead, hparams.nhid, hparams.dropout)\n",
    "        decoder_layers = nn.TransformerDecoderLayer(hparams.ninp, hparams.nhead, hparams.nhid, hparams.dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layers, hparams.nlayers)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layers, hparams.nlayers)\n",
    "        \n",
    "#         self.lin = nn.Linear()\n",
    "#         self.transformer = nn.Transformer(d_model=hparams.ninp, nhead=hparams.nhead, \n",
    "#                                           num_encoder_layers=hparams.nlayers,\n",
    "#                                           num_decoder_layers=hparams.nlayers,\n",
    "#                                           dim_feedforward=hparams.nhid)\n",
    "        self.transformer = nn.Transformer(d_model=hparams.ninp,\n",
    "                                          custom_encoder=self.encoder, \n",
    "                                          custom_decoder = self.decoder)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.lin1 = nn.Linear(hparams.ninp, 50)\n",
    "        self.lin2 = nn.Linear(50, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        print('reading data', flush=True)\n",
    "        self.x = gx\n",
    "        self.y = gy\n",
    "\n",
    "        with open('emb_sz.pkl','rb') as f:\n",
    "            emb_szs = pickle.load(f)\n",
    "        print(f'emb_szs - {emb_szs}')\n",
    "                    \n",
    "        self.embs = nn.ModuleList([nn.Embedding(e[0],e[1]) for e in emb_szs])\n",
    "#         self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "#         self.src_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    @staticmethod\n",
    "    def add_model_specifi_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--bsz', default=20, type=int, help='batch_size', )\n",
    "        parser.add_argument('--src-len', default=90, type=int, help='source length')\n",
    "        parser.add_argument('--tgt-len', default=28, type=int, help='target length')\n",
    "        parser.add_argument('--ninp', default=320, type=int, help='expected features in the input')\n",
    "        parser.add_argument('--nhead', default=4, type=int, help='number of attention heads')\n",
    "        parser.add_argument('--nhid', default=256, type=int, help='dimesion of feed-forward network model')\n",
    "        parser.add_argument('--nlayers', default=2, type=int, help='number of encoder layers')\n",
    "        parser.add_argument('--dropout', default=0.2, type=float, help='dropout')\n",
    "        \n",
    "        # they are not hyper params, but adding them as pytorch lightening can save them\n",
    "        parser.add_argument('--num-cat-cols', default=len(x_cat_cols), type=int, help='number of categorical columns')\n",
    "        parser.add_argument('--num-cont-cols', default=len(x_cont_cols), type=int, help='number of numeric columns')\n",
    "        return parser\n",
    "    \n",
    "#     def _generate_square_subsequent_mask(self, sz):\n",
    "#         # populate the lower triangle with True and rest with False\n",
    "#         return torch.tril(torch.ones(sz, sz)) == 1.0\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_ds = M5DataSet(self.x, self.y, self.hparams.src_len, self.hparams.tgt_len, self.hparams.bsz,dstype='train')  \n",
    "        print(f'train_ds.length - {len(train_ds)}')\n",
    "        train_dl = DataLoader(train_ds, batch_size=1, shuffle=True, pin_memory=True)\n",
    "        return train_dl\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_ds = M5DataSet(self.x, self.y, self.hparams.src_len, self.hparams.tgt_len, self.hparams.bsz, dstype='test1')  \n",
    "        test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "        return test_dl\n",
    "    \n",
    "    def emb_lookups(self, xb, yb=None):\n",
    "        embs_t = []\n",
    "        for idx in range(self.hparams.num_cat_cols):\n",
    "#             print('looking up for ', idx)\n",
    "            embs_t.append(self.embs[idx](xb[:,:,idx].type(torch.long)))\n",
    "        xb_cat = torch.cat(embs_t, dim=2)\n",
    "        xb_cont = xb[:,:,self.hparams.num_cat_cols:]\n",
    "        \n",
    "        if yb is not None:\n",
    "            xb = torch.cat([xb_cat, xb_cont.type(xb_cat.dtype), yb.unsqueeze(2).type(xb_cat.dtype)], dim=2)\n",
    "        else:\n",
    "            xb = torch.cat([xb_cat, xb_cont.type(xb_cat.dtype)], dim=2)\n",
    "            \n",
    "        #pad to adjust the feature dimension\n",
    "        dim3_shortfall = self.hparams.ninp - xb.size(2)\n",
    "        assert dim3_shortfall >= 0\n",
    "        pad = nn.ConstantPad1d(padding=(0,dim3_shortfall),value=0)\n",
    "        xb = pad(xb) \n",
    "\n",
    "        return xb\n",
    "\n",
    "    def forward(self, x_src, y_src, x_tgt):        \n",
    "        x_src = self.emb_lookups(x_src, y_src)\n",
    "        x_tgt = self.emb_lookups(x_tgt)\n",
    "            \n",
    "        x_src = self.pos_encoder(x_src)\n",
    "#         print('shape after pos encoder - ', x_src.size())\n",
    "        out = self.transformer(x_src, x_tgt)\n",
    "#         print('shape after transformer - ', out.size())\n",
    "        out = self.relu(self.lin1(out))\n",
    "        out = self.sigmoid(self.lin2(out))\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x_src, x_tgt, y_src, y_tgt, item_store_mask = batch\n",
    "        x_src = x_src.squeeze(0)\n",
    "        x_tgt = x_tgt.squeeze(0)\n",
    "        y_src = y_src.squeeze(0)\n",
    "        y_tgt = y_tgt.squeeze(0)\n",
    "        \n",
    "#         print(f'x_src.shape - {tuple(x_src.shape)} \\t x_tgt.shape - {tuple(x_tgt.shape)} \\t y_src.shape - {y_src.shape} \\t y_tgt.shape - {y_tgt.shape}')\n",
    "        yhat_tgt = self(x_src, y_src, x_tgt)\n",
    "\n",
    "        # apply the mask (due to random selection of item_stores) to output\n",
    "#         idxs = list(np.arange(0,x_src.size(1)))\n",
    "#         idxs = [1 if o in item_store_mask else 0 for o in idxs]\n",
    "#         mask = torch.tensor(idxs) * torch.ones(y_tgt.size(0), y_tgt.size(1))\n",
    "#         print(f'mask.shape: {mask.shape}')\n",
    "#         \n",
    "        loss = self.criterion((yhat_tgt).reshape(-1).type(torch.float32), (y_tgt).reshape(-1).type(torch.float32))\n",
    "        if batch_idx%10 == 0:\n",
    "            print(f'{batch_idx} loss: {loss}  yhat_tgt.sum: {yhat_tgt.sum().item()}  y_tgt.sum: {y_tgt.sum().item()}')\n",
    "            \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "    \n",
    "#     def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx,\n",
    "#                        second_order_closure=None):\n",
    "#         optimizer.step()\n",
    "#         if batch_idx == 5:\n",
    "#             for name, param in model.named_parameters():\n",
    "#                 if param.requires_grad:\n",
    "#                     pass\n",
    "# #                     print(name, param.grad)\n",
    "#         optimizer.zero_grad()\n",
    "    \n",
    "    def test(self):\n",
    "        dl = self.test_dataloader()\n",
    "        batch = next(iter(dl))\n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_len = 28\n",
    "tgt_len = 28\n",
    "# bsz = 200\n",
    "# model = SalesModel(hparams)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser = SalesModel.add_model_specifi_args(parser)\n",
    "hparams = parser.parse_args('--bsz 1000 --ninp 320 --nhid 512 --nlayers 1'.split())\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='models/weights.ckpt',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model = SalesModel(hparams)\n",
    "\n",
    "wandb_logger = WandbLogger(name='achinta',project='kaggle-m5-forecasting-accuracy')\n",
    "trainer = Trainer(gpus=1,max_epochs=1)\n",
    "trainer.fit(model)\n",
    "trainer.save_checkpoint('models/weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = SalesModel.load_from_checkpoint('models/weights.ckpt')\n",
    "x_src, x_tgt, y_src, y_tgt, item_store_mask = model.test()\n",
    "x_src = x_src.squeeze(0)\n",
    "x_tgt = x_tgt.squeeze(0)\n",
    "y_src = y_src.squeeze(0)\n",
    "y_tgt = y_tgt.squeeze(0)\n",
    "print(f'x_src.shape - {x_src.shape}, x_tgt.shape - {x_tgt.shape} , y_src.shape - {y_src.shape} , y_tgt.shape - {y_tgt.shape}')\n",
    "\n",
    "model.eval()\n",
    "print('starting inference...')\n",
    "yhat_tgt = model(x_src, y_src, x_tgt)\n",
    "yhat_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_tgt = yhat_tgt.refine_names('days','item_store','demand')\n",
    "yhat_tgt_aligned = yhat_tgt.align_to('item_store','days','demand').squeeze(2).detach().numpy()\n",
    "print(f'yhat.shape: ', yhat_tgt_aligned.shape)\n",
    "\n",
    "# create preds df\n",
    "preds = pd.DataFrame()\n",
    "preds['id'] = sales['id']\n",
    "\n",
    "# read scalers\n",
    "with open('scalers.pkl','rb') as f:\n",
    "    scalers = pickle.load(f)\n",
    "\n",
    "\n",
    "pred_ids = preds['id'].tolist()\n",
    "# eval df should also be submitted (days 1942 to 1969)\n",
    "eval_ids = ['_'.join(o.split('_')[:5] + ['evaluation']) for o in pred_ids]\n",
    "eval_df = pd.DataFrame({'id': eval_ids})\n",
    "\n",
    "for idx in range(num_test1_days):\n",
    "    preds['F' + str(idx+1)] = yhat_tgt_aligned[:,idx]\n",
    "    preds['F' + str(idx+1)] = scalers['demand'].inverse_transform(preds[['F' + str(idx+1)]])\n",
    "    \n",
    "    eval_df['F' + str(idx+1)] = 0.0\n",
    "    \n",
    "out_df = pd.concat([preds,eval_df],axis=0)\n",
    "print(out_df.shape)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('preds.csv', index=False)\n",
    "!kaggle competitions submit -c m5-forecasting-accuracy -f preds.csv -m \"transformers 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head preds.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_store_mask = list(np.random.randint(0, 10,3))\n",
    "item_store_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(10).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(hparams)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(data_dir/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
